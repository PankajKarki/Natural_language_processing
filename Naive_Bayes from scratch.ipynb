{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes\n",
    "\n",
    "* Text Preprocessing\n",
    "* Create frequency mappig dictionary\n",
    "* Claculate likelihood with Laplacian smoothing\n",
    "* Calculate log likelihood\n",
    "* Calculate log prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords, twitter_samples   # Library for twitter_samples and stopwords\n",
    "from termcolor import colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 5000\n"
     ]
    }
   ],
   "source": [
    "# get the sets of positive and negative tweets\n",
    "positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "negative_tweets = twitter_samples.strings('negative_tweets.json')\n",
    "\n",
    "# printing length of positive and negative tweets\n",
    "print(len(positive_tweets), len(negative_tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into train and test\n",
    "train_pos = positive_tweets[:4000]\n",
    "train_neg = negative_tweets[:4000]\n",
    "test_pos = positive_tweets[4000:]\n",
    "test_neg = negative_tweets[4000:]\n",
    "\n",
    "X_train = train_pos + train_neg\n",
    "X_test = test_pos + test_neg\n",
    "\n",
    "y_train = np.append(np.ones(len(train_pos)), np.zeros(len(train_neg)))\n",
    "y_test = np.append(np.ones(len(test_pos)), np.zeros(len(test_neg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m#FollowFriday @France_Inte @PKuchly57 @Milipol_Paris for being top engaged members in my community this week :)\u001b[0m\n",
      "\u001b[34m####################################################################################################\u001b[0m\n",
      "\u001b[31m['followfriday', 'top', 'engag', 'member', 'commun', 'week', ':)']\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing\n",
    "from utils import process_tweet\n",
    "\n",
    "print(colored(X_train[0], 'green'))\n",
    "print(colored('#'*100, 'blue'))\n",
    "print(colored(process_tweet(X_train[0]), 'red'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create frequency mappig dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* frequency_mapping_dict = {('happi', 1): 1, ('trick', 0): 1, ('sad', 0): 1, ('tire', 0): 2}\n",
    "* lookup will give out values of a pair from frequency_mapping_dict ex: for pair ('tire', 0) the value is 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "class utils:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.stemmer = PorterStemmer()\n",
    "        self.stopwords_english = stopwords.words('english')\n",
    "        self.tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,\n",
    "                               reduce_len=True)\n",
    "    \n",
    "    def pre_process(self, text):\n",
    "        text = re.sub(r'\\$\\w*', '', text)\n",
    "        text = re.sub(r'^RT[\\s]+', '', text)\n",
    "        text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text)\n",
    "        text = re.sub(r'#', '', text)\n",
    "        text_tokens = self.tokenizer.tokenize(text)\n",
    "\n",
    "        text_clean = []\n",
    "        for word in text_tokens:\n",
    "            if (word not in self.stopwords_english and  # remove stopwords\n",
    "                word not in string.punctuation):  # remove punctuation\n",
    "                # tweets_clean.append(word)\n",
    "                stem_word = self.stemmer.stem(word)  # stemming word\n",
    "                text_clean.append(stem_word)\n",
    "        return text_clean\n",
    "    \n",
    "    def build_frequency(self, X, y):\n",
    "        freq = {}\n",
    "        for text, label in zip(X, y):\n",
    "            for word in self.pre_process(text):\n",
    "                pair = (word, label)\n",
    "                freq[pair] = freq.get(pair, 0) +1\n",
    "        return freq\n",
    "    \n",
    "    def look_up(self, freqs, word, label):\n",
    "        n = 0\n",
    "        pair = (word, label)\n",
    "        if (pair in freqs):\n",
    "            n = freqs[pair]\n",
    "        return n\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* NBpred method predicts for a single tweet\n",
    "* predict method gives prediction for the entire batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.utils = utils()\n",
    "        self.logprior = None\n",
    "        self.loglikelihood = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.loglikelihood = {}\n",
    "        self.logprior = 0\n",
    "        freqs = self.utils.build_frequency(X, y)\n",
    "        Vocab = set([pair[0] for pair in freqs.keys()])\n",
    "        V = len(Vocab)\n",
    "        \n",
    "        total_pos = total_neg = 0\n",
    "        for pair in freqs.keys():\n",
    "            if pair[1]>0:\n",
    "                total_pos += freqs[pair]\n",
    "            else:\n",
    "                total_neg += freqs[pair]\n",
    "\n",
    "        D_pos = (len(list(filter(lambda x: x > 0, y_train))))\n",
    "        D_neg = (len(list(filter(lambda x: x <= 0, y_train))))\n",
    "        \n",
    "        # Calculate log prior\n",
    "        self.logprior = np.log(D_pos) - np.log(D_neg)\n",
    "        \n",
    "        # Calculate positive and negative frequency\n",
    "        for word in Vocab:\n",
    "            pos_freq = self.utils.look_up(freqs, word, 1)\n",
    "            neg_freq = self.utils.look_up(freqs, word, 0)\n",
    "            \n",
    "            # Calculate the probability that each word is positive, and negative\n",
    "            p_pos = (pos_freq + 1) / (total_pos + V)\n",
    "            p_neg = (neg_freq + 1) / (total_neg + V)\n",
    "            \n",
    "            # Claculate loglikelihood\n",
    "            self.loglikelihood[word] = np.log(p_pos/p_neg)\n",
    "            \n",
    "    \n",
    "    def NB_pred(self, x):\n",
    "        p = 0\n",
    "        p += self.logprior\n",
    "\n",
    "        for word in self.utils.pre_process(x):\n",
    "            if word in self.loglikelihood:\n",
    "                p += self.loglikelihood[word]\n",
    "\n",
    "        return p\n",
    "        \n",
    "    def predict(self, X):\n",
    "        y_hats = []\n",
    "        for tweet in X:\n",
    "            # if the prediction is > 0\n",
    "            if self.NB_pred(tweet) > 0:\n",
    "                y_hat_i = 1\n",
    "            else:\n",
    "                y_hat_i = 0\n",
    "\n",
    "            y_hats.append(y_hat_i)\n",
    "        return y_hats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = NaiveBayes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 9085\n"
     ]
    }
   ],
   "source": [
    "print(clf.logprior, len(clf.loglikelihood))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hats = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = np.mean(np.absolute(y_hats-y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.006\n",
      "0.994\n"
     ]
    }
   ],
   "source": [
    "accuracy = 1-error\n",
    "print(error)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The expected output is 1.5737794405738943\n"
     ]
    }
   ],
   "source": [
    "my_tweet = 'She smiled.'\n",
    "p = clf.NB_pred(my_tweet)\n",
    "print('The expected output is', p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "She smiled. -> 1.57\n",
      "I am happy -> 2.15\n",
      "I am bad -> -1.29\n",
      "this movie should have been great. -> 2.14\n",
      "great -> 2.14\n",
      "great great -> 4.28\n",
      "great great great -> 6.41\n",
      "great great great great -> 8.55\n"
     ]
    }
   ],
   "source": [
    "l = ['She smiled.', 'I am happy', 'I am bad', 'this movie should have been great.', 'great', 'great great', 'great great great', 'great great great great']\n",
    "for tweet in l:\n",
    "    p = clf.NB_pred(tweet)\n",
    "    print(f'{tweet} -> {p:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-8.802119484044237"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tweet = 'you are bad :('\n",
    "clf.NB_pred(my_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Analysis on misclassified points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truth Predicted Tweet\n",
      "1\t0.00\tb''\n",
      "1\t0.00\tb'truli later move know queen bee upward bound movingonup'\n",
      "1\t0.00\tb'new report talk burn calori cold work harder warm feel better weather :p'\n",
      "1\t0.00\tb'harri niall 94 harri born ik stupid wanna chang :D'\n",
      "1\t0.00\tb''\n",
      "1\t0.00\tb''\n",
      "1\t0.00\tb'park get sunlight'\n",
      "1\t0.00\tb'uff itna miss karhi thi ap :p'\n",
      "0\t1.00\tb'hello info possibl interest jonatha close join beti :( great'\n",
      "0\t1.00\tb'u prob fun david'\n",
      "0\t1.00\tb'pat jay'\n",
      "0\t1.00\tb'whatev stil l young >:-('\n"
     ]
    }
   ],
   "source": [
    "# Some error analysis done for you\n",
    "print('Truth Predicted Tweet')\n",
    "for x, y in zip(X_test, y_test):\n",
    "    y_hat = clf.NB_pred(x)\n",
    "    if y != (np.sign(y_hat) > 0):\n",
    "        print('%d\\t%0.2f\\t%s' % (y, np.sign(y_hat) > 0, ' '.join(process_tweet(x)).encode('ascii', 'ignore')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretability in naive bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### positive negative ratio\n",
    "* {'positive': 161, 'negative': 18, 'ratio': 8.526315789473685}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = utils()\n",
    "\n",
    "def get_ratio(freqs, word):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        freqs: frequency mapping of positive and negative words\n",
    "        \n",
    "    Output: a dictionary with keys: \"positive\", \"negative\", \"ratio\"\n",
    "    \"\"\"\n",
    "    pos_neg_ratio = {'positive': 0, 'negative': 0, 'ratio': 0.0}\n",
    "    \n",
    "    pos_neg_ratio['positive'] =  u.look_up(freqs, word, 1)\n",
    "    pos_neg_ratio['negative'] = u.look_up(freqs, word, 0) \n",
    "    \n",
    "    pos_neg_ratio['ratio'] = (pos_neg_ratio['positive'] + 1)/(pos_neg_ratio['negative'] + 1)\n",
    "    \n",
    "    return pos_neg_ratio\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'positive': 161, 'negative': 18, 'ratio': 8.526315789473685}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs = u.build_frequency(X_train, y_train)\n",
    "get_ratio(freqs, 'happi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_by_threshold(freqs, label, threshold):\n",
    "    '''\n",
    "    Input:\n",
    "        freqs: dictionary of words\n",
    "        pos_neg_ratio: dictionary of positive counts, negative counts, and ratio of positive / negative counts.\n",
    "        label: 1 for positive, 0 for negative\n",
    "        threshold: ratio that will be used as the cutoff for including a word in the returned dictionary\n",
    "    Output:\n",
    "        word_set: dictionary containing the word and information on its positive count, negative count, and ratio of positive to negative counts.\n",
    "        example of a key value pair:\n",
    "        {'happi':\n",
    "            {'positive': 10, 'negative': 20, 'ratio': 0.5}\n",
    "        }\n",
    "    '''\n",
    "    word_list = {}\n",
    "\n",
    "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
    "    for key in freqs.keys():\n",
    "        word, _ = key\n",
    "\n",
    "        # get the positive/negative ratio for a word\n",
    "        pos_neg_ratio = get_ratio(freqs, word)\n",
    "\n",
    "        # if the label is 1 and the ratio is greater than or equal to the threshold...\n",
    "        if label == 1 and pos_neg_ratio['ratio'] >= threshold :\n",
    "\n",
    "            # Add the pos_neg_ratio to the dictionary\n",
    "            word_list[word] = pos_neg_ratio\n",
    "\n",
    "        # If the label is 0 and the pos_neg_ratio is less than or equal to the threshold...\n",
    "        elif label == 0 and pos_neg_ratio['ratio'] <= threshold:\n",
    "            # Add the pos_neg_ratio to the dictionary\n",
    "            word_list[word] = pos_neg_ratio\n",
    "\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{':(': {'positive': 1, 'negative': 3663, 'ratio': 0.0005458515283842794},\n",
       " ':-(': {'positive': 0, 'negative': 378, 'ratio': 0.002638522427440633},\n",
       " 'zayniscomingbackonjuli': {'positive': 0, 'negative': 19, 'ratio': 0.05},\n",
       " '26': {'positive': 0, 'negative': 20, 'ratio': 0.047619047619047616},\n",
       " '>:(': {'positive': 0, 'negative': 43, 'ratio': 0.022727272727272728},\n",
       " 'lost': {'positive': 0, 'negative': 19, 'ratio': 0.05},\n",
       " '♛': {'positive': 0, 'negative': 210, 'ratio': 0.004739336492890996},\n",
       " '》': {'positive': 0, 'negative': 210, 'ratio': 0.004739336492890996},\n",
       " 'beli̇ev': {'positive': 0, 'negative': 35, 'ratio': 0.027777777777777776},\n",
       " 'wi̇ll': {'positive': 0, 'negative': 35, 'ratio': 0.027777777777777776},\n",
       " 'justi̇n': {'positive': 0, 'negative': 35, 'ratio': 0.027777777777777776},\n",
       " 'ｓｅｅ': {'positive': 0, 'negative': 35, 'ratio': 0.027777777777777776},\n",
       " 'ｍｅ': {'positive': 0, 'negative': 35, 'ratio': 0.027777777777777776}}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test your function: find negative words at or below a threshold\n",
    "get_words_by_threshold(freqs, label=0, threshold=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'followfriday': {'positive': 23, 'negative': 0, 'ratio': 24.0},\n",
       " 'commun': {'positive': 27, 'negative': 1, 'ratio': 14.0},\n",
       " ':)': {'positive': 2847, 'negative': 2, 'ratio': 949.3333333333334},\n",
       " 'flipkartfashionfriday': {'positive': 16, 'negative': 0, 'ratio': 17.0},\n",
       " ':D': {'positive': 498, 'negative': 0, 'ratio': 499.0},\n",
       " ':p': {'positive': 103, 'negative': 0, 'ratio': 104.0},\n",
       " 'influenc': {'positive': 16, 'negative': 0, 'ratio': 17.0},\n",
       " ':-)': {'positive': 543, 'negative': 0, 'ratio': 544.0},\n",
       " \"here'\": {'positive': 20, 'negative': 0, 'ratio': 21.0},\n",
       " 'youth': {'positive': 14, 'negative': 0, 'ratio': 15.0},\n",
       " 'bam': {'positive': 44, 'negative': 0, 'ratio': 45.0},\n",
       " 'warsaw': {'positive': 44, 'negative': 0, 'ratio': 45.0},\n",
       " 'shout': {'positive': 11, 'negative': 0, 'ratio': 12.0},\n",
       " ';)': {'positive': 22, 'negative': 0, 'ratio': 23.0},\n",
       " 'stat': {'positive': 51, 'negative': 0, 'ratio': 52.0},\n",
       " 'arriv': {'positive': 57, 'negative': 4, 'ratio': 11.6},\n",
       " 'via': {'positive': 60, 'negative': 1, 'ratio': 30.5},\n",
       " 'glad': {'positive': 41, 'negative': 2, 'ratio': 14.0},\n",
       " 'blog': {'positive': 27, 'negative': 0, 'ratio': 28.0},\n",
       " 'fav': {'positive': 11, 'negative': 0, 'ratio': 12.0},\n",
       " 'fback': {'positive': 26, 'negative': 0, 'ratio': 27.0},\n",
       " 'pleasur': {'positive': 10, 'negative': 0, 'ratio': 11.0}}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test your function; find positive words at or above a threshold\n",
    "get_words_by_threshold(freqs, label=1, threshold=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
